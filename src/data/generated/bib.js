const generatedBibEntries = {
    "bagirov2023finding": {
        "abstract": "Finding compact and well-separated clusters in data sets is a challenging task. Most clustering algorithms try to minimize certain clustering objective functions. These functions usually reflect the intra-cluster similarity and inter-cluster dissimilarity. However, the use of such functions alone may not lead to the finding of well-separated and, in some cases, compact clusters. Therefore additional measures, called cluster validity indices, are used to estimate the true number of well-separated and compact clusters. Some of these indices are well-suited to be included into the optimization model of the clustering problem. Silhouette coefficients are among such indices. In this paper, a new optimization model of the clustering problem is developed where the clustering function is used as an objective and silhouette coefficients are used to formulate constraints. Then an algorithm, called CLUSCO (CLustering Using Silhouette COefficients), is designed to construct clusters incrementally. Three schemes are discussed to reduce the computational complexity of the algorithm. Its performance is evaluated using fourteen real-world data sets and compared with that of three state-of-the-art clustering algorithms. Results show that the CLUSCO is able to compute compact clusters which are significantly better separable in comparison with those obtained by other algorithms.",
        "author": "Bagirov, Adil M and Aliguliyev, Ramiz M and Sultanova, Nargiz",
        "doi": "10.1016/j.patcog.2022.109144",
        "image": "bagirov2023finding.png",
        "journal": "Pattern Recognition",
        "keywords": "type:method, cluster_analysis, silhouette_coefficients, cluster_validity, nonsmooth_optimization, incremental_algorithm, year:2023, method_category:metric-centric",
        "pages": "109144",
        "publisher": "Elsevier",
        "series": "PatternRec",
        "title": "Finding compact and well-separated clusters: Clustering using silhouette coefficients",
        "type": "article",
        "url": "https://doi.org/10.1016/j.patcog.2022.109144",
        "volume": "135",
        "year": "2023"
    },
    "fuchs2019educlust": {
        "abstract": "We present EduClust, a visualization application for teaching clustering algorithms. EduClust is an online application that combines visualizations, interactions, and animations to facilitate the understanding and teaching of clustering steps, parameters, and procedures. Traditional classroom settings aim for cognitive processes like remembering and understanding. We designed EduClust for expanded educational objectives like applying and evaluating. Educators can use the tool in class to show the effect of different clustering parameters on various datasets while animating through each algorithm\u2019s steps, but also use the tool to prepare traditional teaching material quickly by exporting animations and images. Students, on the other hand, benefit from the ability to compare and contrast the influence of clustering parameters on different datasets, while seeing technical details such as pseudocode and step-by-step explanations.",
        "author": "Fuchs, Johannes and Isenberg, Petra and Bezerianos, Anastasia and Miller, Matthias and Keim, Daniel A",
        "doi": "10.1109/mcg.2020.2970560",
        "image": "fuchs2019educlust.png",
        "journal": "IEEE Computer Graphics and Applications",
        "keywords": "type:system, visualization, clustering_algorithms, educational_tool, teaching_application, interactive_learning, year:2019, method_category:teaching-tool",
        "publisher": "IEEE",
        "series": "IEEE CGA",
        "title": "EduClust: A visualization application for teaching clustering algorithms",
        "type": "article",
        "url": "https://doi.org/10.1109/mcg.2020.2970560",
        "year": "2019"
    },
    "januzaj2023determining": {
        "abstract": "The identification of the same objects is very important in determining the similarity between different objects. Nowadays, there are several techniques that allow us to divide objects into different groups that differ from one to another. In order to have the best separation between the clusters, it is required that the optimal determination of the number of clusters of a corpus be made in advance. In our research, the Silhouette score technique was used in order to make the optimal determination of this number of clusters. The application of such a technique was done through the Python language, and a corpus of unstructured job vacancy data was used. After determining the optimal number, at the end we present these clusters and the similarity between them, this presentation will be done in the form of a graph in a suitable format.",
        "author": "Januzaj, Ylber and Beqiri, Edmond and Luma, Artan",
        "doi": "10.3991/ijoe.v19i04.37059",
        "image": "januzaj2023determining.png",
        "journal": "International Journal of Online \\& Biomedical Engineering",
        "keywords": "type:application, silhouette_score, clusters, data_mining, corpus, job_vacancy, year:2023, method_category:metric-centric",
        "number": "4",
        "publisher": "OnlineJournals.org",
        "series": "IJOE",
        "title": "Determining the Optimal Number of Clusters using Silhouette Score as a Data Mining Technique.",
        "type": "article",
        "url": "https://doi.org/10.3991/ijoe.v19i04.37059",
        "volume": "19",
        "year": "2023"
    },
    "rousseeuw1987silhouettes": {
        "abstract": "A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an 'appropriate' number of clusters.",
        "author": "Rousseeuw, Peter J",
        "doi": "10.1016/0377-0427(87)90125-7",
        "image": "rousseeuw1987silhouettes.png",
        "journal": "Journal of Computational and Applied Mathematics",
        "keywords": "type:method, graphical_display, cluster_analysis, clustering_validity, classification, year:1987, method_category:metric-centric",
        "number": "",
        "pages": "53--65",
        "publisher": "Elsevier",
        "series": "JCAM",
        "title": "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis",
        "type": "article",
        "url": "https://doi.org/10.1016/0377-0427(87)90125-7",
        "volume": "20",
        "year": "1987"
    },
    "schubert2023stop": {
        "abstract": "A major challenge when using k-means clustering often is how to choose the parameter k, the number of clusters. In this letter, we want to point out that it is very easy to draw poor conclusions from a common heuristic, the \"elbow method\". Better alternatives have been known in literature for a long time, and we want to draw attention to some of these easy to use options, that often perform better. This letter is a call to stop using the elbow method altogether, because it severely lacks theoretic support, and we want to encourage educators to discuss the problems of the method\u2014if introducing it in class at all\u2014and teach alternatives instead, while researchers and reviewers should reject conclusions drawn from the elbow method.",
        "author": "Schubert, Erich",
        "doi": "10.1145/3606274.3606278",
        "image": "schubert2023stop.png",
        "journal": "ACM SIGKDD Explorations Newsletter",
        "keywords": "type:opinion, elbow_method, k-means, cluster_number_selection, clustering_criticism, alternatives, year:2023, method_category:visual-comparison",
        "number": "1",
        "pages": "36--42",
        "publisher": "ACM New York, NY, USA",
        "series": "SIGKDD",
        "title": "Stop using the elbow criterion for k-means and how to choose the number of clusters instead",
        "type": "article",
        "url": "https://doi.org/10.1145/3606274.3606278",
        "volume": "25",
        "year": "2023"
    },
    "shi2021quantitative": {
        "abstract": "Clustering, a traditional machine learning method, plays a significant role in data analysis. Most clustering algorithms depend on a predetermined exact number of clusters, whereas, in practice, clusters are usually unpredictable. Although the Elbow method is one of the most commonly used methods to discriminate the optimal cluster number, the discriminant of the number of clusters depends on the manual identification of the elbow points on the visualization curve. Thus, experienced analysts cannot clearly identify the elbow point from the plotted curve when the plotted curve is fairly smooth. To solve this problem, a new elbow point discriminant method is proposed to yield a statistical metric that estimates an optimal cluster number when clustering on a dataset. First, the average degree of distortion obtained by the Elbow method is normalized to the range of 0 to 10. Second, the normalized results are used to calculate the cosine of intersection angles between elbow points. Third, this calculated cosine of intersection angles and the arccosine theorem are used to compute the intersection angles between elbow points. Finally, the index of the above-computed minimal intersection angles between elbow points is used as the estimated potential optimal cluster number. The experimental results based on simulated datasets and a well-known public dataset (Iris Dataset) demonstrated that the estimated optimal cluster number obtained by our newly proposed method is better than the widely used Silhouette method.",
        "author": "Shi, Congming and Wei, Bingtao and Wei, Shoulin and Wang, Wen and Liu, Hai and Liu, Jialei",
        "doi": "10.1186/s13638-021-01910-w",
        "image": "shi2021quantitative.png",
        "journal": "EURASIP Journal on Wireless Communications and Networking",
        "keywords": "type:method, machine_learning, clustering, elbow_method, silhouette_coefficient, cosine_law, year:2021, method_category:visual-comparison",
        "pages": "1--16",
        "publisher": "Springer",
        "series": "EURASIP JWC",
        "title": "A quantitative discriminant method of elbow point for the optimal number of clusters in clustering algorithm",
        "type": "article",
        "url": "https://doi.org/10.1186/s13638-021-01910-w",
        "volume": "2021",
        "year": "2021"
    },
    "shutaywi2021silhouette": {
        "abstract": "Grouping the objects based on their similarities is an important common task in machine learning applications. Many clustering methods have been developed, among them k-means based clustering methods have been broadly used and several extensions have been developed to improve the original k-means clustering method such as k-means ++ and kernel k-means. K-means is a linear clustering method; that is, it divides the objects into linearly separable groups, while kernel k-means is a non-linear technique. Kernel k-means projects the elements to a higher dimensional feature space using a kernel function, and then groups them. Different kernel functions may not perform similarly in clustering of a data set and, in turn, choosing the right kernel for an application could be challenging. In our previous work, we introduced a weighted majority voting method for clustering based on normalized mutual information (NMI). NMI is a supervised method where the true labels for a training set are required to calculate NMI. In this study, we extend our previous work of aggregating the clustering results to develop an unsupervised weighting function where a training set is not available. The proposed weighting function here is based on Silhouette index, as an unsupervised criterion. As a result, a training set is not required to calculate Silhouette index. This makes our new method more sensible in terms of clustering concept.",
        "author": "Shutaywi, Meshal and Kachouie, Nezamoddin N",
        "doi": "10.3390/e23060759",
        "image": "shutaywi2021silhouette.png",
        "journal": "Entropy",
        "keywords": "type:method, k-means, kernel_k-means, machine_learning, nonlinear_clustering, silhouette_index, weighted_clustering, year:2021, method_category:metric-centric",
        "number": "6",
        "pages": "759",
        "publisher": "MDPI",
        "series": "Entropy",
        "title": "Silhouette analysis for performance evaluation in machine learning with applications to clustering",
        "type": "article",
        "url": "https://doi.org/10.3390/e23060759",
        "volume": "23",
        "year": "2021"
    },
    "sun2024circular": {
        "abstract": "There is a growing interest in characterizing circular data found in biological systems. Such data are wide-ranging and varied, from the signal phase in neural recordings to nucleotide sequences in round genomes. Traditional clustering algorithms are often inadequate due to their limited ability to distinguish differences in the periodic component \u03b8. Current clustering schemes for polar coordinate systems have limitations, such as being only angle-focused or lacking generality. To overcome these limitations, we propose a new analysis framework that utilizes projections onto a cylindrical coordinate system to represent objects in a polar coordinate system optimally. Using the mathematical properties of circular data, we show that our approach always finds the correct clustering result within the reconstructed dataset, given sufficient periodic repetitions of the data. This framework is generally applicable and adaptable to most state-of-the-art clustering algorithms. We demonstrate on synthetic and real data that our method generates more appropriate and consistent clustering results than standard methods. In summary, our proposed analysis framework overcomes the limitations of existing polar coordinate-based clustering methods and provides an accurate and efficient way to cluster circular data.",
        "author": "Sun, Xiaoxiao and Sajda, Paul",
        "doi": "10.1109/tcbb.2024.3406341",
        "image": "sun2024circular.png",
        "journal": "IEEE/ACM Transactions on Computational Biology and Bioinformatics",
        "keywords": "type:method, circular_clustering, polar_coordinates, coordinate_reconstruction, phase_synchronization, circular_DNA, year:2024, method_category:visual-comparison",
        "publisher": "IEEE",
        "series": "TCBB",
        "title": "Circular Clustering With Polar Coordinate Reconstruction",
        "type": "article",
        "url": "https://doi.org/10.1109/tcbb.2024.3406341",
        "year": "2024"
    },
    "tibshirani2001estimating": {
        "abstract": "We propose a method (the \u2018gap statistic\u2019) for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.",
        "author": "Tibshirani, Robert and Walther, Guenther and Hastie, Trevor",
        "doi": "10.1111/1467-9868.00293",
        "image": "tibshirani2001estimating.png",
        "journal": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)",
        "keywords": "type:method, gap_statistic, clustering, cluster_validation, statistical_analysis, year:2001, method_category:metric-centric",
        "number": "2",
        "pages": "411--423",
        "publisher": "Wiley Online Library",
        "series": "JRSSB",
        "title": "Estimating the number of clusters in a data set via the gap statistic",
        "type": "article",
        "url": "https://doi.org/10.1111/1467-9868.00293",
        "volume": "63",
        "year": "2001"
    },
    "xu2016reviews": {
        "abstract": "Clustering analysis seeks to partition a given dataset into groups or clusters so that the data objects within a cluster are more similar to each other than the objects in different clusters. A very rich literature on clustering analysis has developed over the past three decades. But a crucial question still remains unanswered: how many clusters are contained in the population on earth when only an observed set of samples is available? The goal of this paper is to provide a comprehensive review of approaches on determining the \"correct\" number of clusters. In particular, we divide these approaches into three categories: internal measures, external measures, and clustering stability based methods. Then, we introduce several representative examples, and present specific challenges pertinent to each category. Finally, the promising trends are suggested in this field.",
        "author": "Xu, Shuo and Qiao, Xiaodong and Zhu, Lijun and Zhang, Yunliang and Xue, Chunxiang and Li, Lin",
        "doi": "10.18576/amis/100428",
        "image": "xu2016reviews.png",
        "journal": "Applied Mathematics \\& Information Sciences",
        "keywords": "type:survey, internal_measures, external_measures, clustering_stability, cluster_validation, year:2016, method_category:metric-centric",
        "number": "4",
        "publisher": "Natural Sciences Publishing",
        "series": "AMIS",
        "title": "Reviews on determining the number of clusters",
        "type": "article",
        "url": "https://doi.org/10.18576/amis/100428",
        "volume": "10",
        "year": "2016"
    }
};